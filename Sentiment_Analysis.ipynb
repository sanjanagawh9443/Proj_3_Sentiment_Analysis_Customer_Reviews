{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df0dfec-f0e4-49a6-85dc-2ce041aac282",
   "metadata": {},
   "source": [
    "# Load Dataset and Preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7755bb5c-43cc-431f-a434-2c51ac91b020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I love this product! It's absolutely amazing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This is the worst thing I have ever bought.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>What a great experience. Will use again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I hate this. Waste of money and time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent quality and fast delivery.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                           text\n",
       "0          1  I love this product! It's absolutely amazing.\n",
       "1          0    This is the worst thing I have ever bought.\n",
       "2          1       What a great experience. Will use again.\n",
       "3          0          I hate this. Waste of money and time.\n",
       "4          1           Excellent quality and fast delivery."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"sentiment_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a51f58-35b0-42af-984f-8d3b574aad7c",
   "metadata": {},
   "source": [
    "# DataFrame Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c461be1-5859-4dfc-acb1-d2d1e03e4660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of    sentiment                                           text\n",
       "0          1  I love this product! It's absolutely amazing.\n",
       "1          0    This is the worst thing I have ever bought.\n",
       "2          1       What a great experience. Will use again.\n",
       "3          0          I hate this. Waste of money and time.\n",
       "4          1           Excellent quality and fast delivery.\n",
       "5          0            Very disappointed with the service.\n",
       "6          1                  Highly recommend to everyone.\n",
       "7          0                  Not good. Completely useless.\n",
       "8          1                Fantastic! Beyond expectations.\n",
       "9          0             Won’t buy again. Terrible product.>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747df4a-9a61-4a4c-baeb-1f94b1abc240",
   "metadata": {},
   "source": [
    "# Missing Values Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ad6638-0300-40ed-9fb8-48c89ba1a9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecd03d-d3d0-4880-8f10-47609851785c",
   "metadata": {},
   "source": [
    "# Convert Text to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a16846ec-1850-4164-b459-58d960feeea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i love this product its absolutely amazing\n",
       "1    this is the worst thing i have ever bought\n",
       "2        what a great experience will use again\n",
       "3           i hate this waste of money and time\n",
       "4           excellent quality and fast delivery\n",
       "5            very disappointed with the service\n",
       "6                  highly recommend to everyone\n",
       "7                   not good completely useless\n",
       "8                 fantastic beyond expectations\n",
       "9              won’t buy again terrible product\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "df['text'] = df['text'].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)\n",
    "df['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ff1b4c-1024-4d76-b232-a73092525d6c",
   "metadata": {},
   "source": [
    "# Remove Punctuation from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf0aaf1-883b-4780-8034-37e15cd56c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i love this product! it's absolutely amazing.\n",
       "1      this is the worst thing i have ever bought.\n",
       "2         what a great experience. will use again.\n",
       "3            i hate this. waste of money and time.\n",
       "4             excellent quality and fast delivery.\n",
       "5              very disappointed with the service.\n",
       "6                    highly recommend to everyone.\n",
       "7                    not good. completely useless.\n",
       "8                  fantastic! beyond expectations.\n",
       "9               won’t buy again. terrible product.\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].str.lower()\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8d381-54a5-401c-8702-a825670d5691",
   "metadata": {},
   "source": [
    "# Remove Stopwords from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8a06e35-bca0-4276-9f0c-f13341d55a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SANJANA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    love product absolutely amazing\n",
       "1            worst thing ever bought\n",
       "2               great experience use\n",
       "3              hate waste money time\n",
       "4    excellent quality fast delivery\n",
       "5               disappointed service\n",
       "6          highly recommend everyone\n",
       "7            good completely useless\n",
       "8      fantastic beyond expectations\n",
       "9         won’t buy terrible product\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in stop])\n",
    "\n",
    "df['text'] = df['text'].apply(remove_stopwords)\n",
    "df['text'].head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeff5c2-b8f3-42fa-ba1c-91684770d5d9",
   "metadata": {},
   "source": [
    "# Display First Few Rows of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34252737-2e8b-4751-850f-3687894c0671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                           text\n",
      "0          1  I love this product! It's absolutely amazing.\n",
      "1          0    This is the worst thing I have ever bought.\n",
      "2          1       What a great experience. Will use again.\n",
      "3          0          I hate this. Waste of money and time.\n",
      "4          1           Excellent quality and fast delivery.\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d0a71-a8b2-4660-acf2-1b3d918120d1",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorization and Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab16ecf-a7a4-4c99-84c3-30b5a539db9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (10, 33)\n",
      "Features (words): ['absolutely' 'amazing' 'beyond' 'bought' 'buy' 'completely' 'delivery'\n",
      " 'disappointed' 'ever' 'everyone' 'excellent' 'expectations' 'experience'\n",
      " 'fantastic' 'fast' 'good' 'great' 'hate' 'highly' 'love' 'money'\n",
      " 'product' 'quality' 'recommend' 'service' 'terrible' 'thing' 'time' 'use'\n",
      " 'useless' 'waste' 'won' 'worst']\n",
      "Sample sentiment labels:\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['sentiment']\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", X.shape)\n",
    "print(\"Features (words):\", vectorizer.get_feature_names_out())\n",
    "print(\"Sample sentiment labels:\")\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8319bc3-5e44-4064-8a64-7cec402e7c73",
   "metadata": {},
   "source": [
    "# Train-Test Split of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8ffdd7a-3536-4bc3-b7dc-02297dde94da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8, 33)\n",
      "X_test shape: (2, 33)\n",
      "y_train shape: (8,)\n",
      "y_test shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1437158-d417-4e2e-a7b3-dd9d2e0a50f5",
   "metadata": {},
   "source": [
    "# Train Logistic Regression Model and Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1512da94-9d8b-456e-9d53-5a10aaa96ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n",
      "Test Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = model.score(X_train, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f19fe3-26e5-4b10-8be4-0dadfdc9f3f6",
   "metadata": {},
   "source": [
    "# Model Prediction and Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d2284a1-e9b7-44f5-b37d-5510a87e630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ecacf-07fa-4274-9d97-53c4cc6dffd7",
   "metadata": {},
   "source": [
    "# Sentiment Prediction Function and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "937e5893-614f-49d1-8a86-04a99d63a9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    text = text.lower()\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    text = \" \".join([word for word in text.split() if word not in stop])\n",
    "    text_vec = vectorizer.transform([text])\n",
    "    pred = model.predict(text_vec)\n",
    "    return \"Positive\" if pred[0] == 1 else \"Negative\"\n",
    "\n",
    "print(predict_sentiment(\"I really love this product!\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb971a-54f7-4463-81b4-c8a86d5a8078",
   "metadata": {},
   "source": [
    "# Sentiment Prediction Function with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53601c75-16b2-42e4-91ab-186e4e1acdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    text = text.lower()\n",
    "    text = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    text = \" \".join([word for word in text.split() if word not in stop])\n",
    "    text_vec = vectorizer.transform([text])\n",
    "    pred = model.predict(text_vec)\n",
    "    return \"Positive\" if pred[0] == 1 else \"Negative\"\n",
    "\n",
    "print(predict_sentiment(\"I absolutely love this!\"))\n",
    "print(predict_sentiment(\"This is a waste of money\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
